{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb145028",
   "metadata": {},
   "source": [
    "# Example: Isomap on Faces\n",
    "One place manifold learning is often used is in understanding the relationship\n",
    "between high-dimensional data points. A common case of high-dimensional data is\n",
    "images; for example, a set of images with 1,000 pixels each can be thought of as col‐\n",
    "lection of points in 1,000 dimensions—the brightness of each pixel in each image\n",
    "defines the coordinate in that dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77550c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef756f37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file '/home/qalmaqihir/scikit_learn_data/lfw_home/lfw_funneled/Alejandro_Toledo/Alejandro_Toledo_0031.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# from sklearn.datasets import fetch_lfw_people\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# faces = fetch_lfw_people(min_faces_per_person=30)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# faces.data.shape\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_lfw_people\n\u001b[0;32m----> 6\u001b[0m faces \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_lfw_people\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_faces_per_person\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m faces\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/datasets/_lfw.py:330\u001b[0m, in \u001b[0;36mfetch_lfw_people\u001b[0;34m(data_home, funneled, resize, min_faces_per_person, color, slice_, download_if_missing, return_X_y)\u001b[0m\n\u001b[1;32m    327\u001b[0m load_func \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mcache(_fetch_lfw_people)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# load and memoize the pairs as np arrays\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m faces, target, target_names \u001b[38;5;241m=\u001b[39m \u001b[43mload_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_folder_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_faces_per_person\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_faces_per_person\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mslice_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m X \u001b[38;5;241m=\u001b[39m faces\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mlen\u001b[39m(faces), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    340\u001b[0m fdescr \u001b[38;5;241m=\u001b[39m load_descr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlfw.rst\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/memory.py:594\u001b[0m, in \u001b[0;36mMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cached_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/memory.py:537\u001b[0m, in \u001b[0;36mMemorizedFunc._cached_call\u001b[0;34m(self, args, kwargs, shelving)\u001b[0m\n\u001b[1;32m    534\u001b[0m         must_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m must_call:\n\u001b[0;32m--> 537\u001b[0m     out, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmmap_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    539\u001b[0m         \u001b[38;5;66;03m# Memmap the output at the first call to be consistent with\u001b[39;00m\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;66;03m# later calls\u001b[39;00m\n\u001b[1;32m    541\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verbose:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/memory.py:779\u001b[0m, in \u001b[0;36mMemorizedFunc.call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28mprint\u001b[39m(format_call(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, args, kwargs))\n\u001b[0;32m--> 779\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore_backend\u001b[38;5;241m.\u001b[39mdump_item(\n\u001b[1;32m    781\u001b[0m     [func_id, args_id], output, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verbose)\n\u001b[1;32m    783\u001b[0m duration \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/datasets/_lfw.py:219\u001b[0m, in \u001b[0;36m_fetch_lfw_people\u001b[0;34m(data_folder_path, slice_, color, resize, min_faces_per_person)\u001b[0m\n\u001b[1;32m    216\u001b[0m target_names \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(person_names)\n\u001b[1;32m    217\u001b[0m target \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msearchsorted(target_names, person_names)\n\u001b[0;32m--> 219\u001b[0m faces \u001b[38;5;241m=\u001b[39m \u001b[43m_load_imgs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;66;03m# shuffle the faces with a deterministic RNG scheme to avoid having\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# all faces of the same person in a row, as it would break some\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m# cross validation and learning algorithms such as SGD and online\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;66;03m# k-means that make an IID assumption\u001b[39;00m\n\u001b[1;32m    226\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(n_faces)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/datasets/_lfw.py:161\u001b[0m, in \u001b[0;36m_load_imgs\u001b[0;34m(file_paths, slice_, color, resize)\u001b[0m\n\u001b[1;32m    157\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading face #\u001b[39m\u001b[38;5;132;01m%05d\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m%05d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, n_faces)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# Checks if jpeg reading worked. Refer to issue #3594 for more\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# details.\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m pil_img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m pil_img\u001b[38;5;241m.\u001b[39mcrop((w_slice\u001b[38;5;241m.\u001b[39mstart, h_slice\u001b[38;5;241m.\u001b[39mstart, w_slice\u001b[38;5;241m.\u001b[39mstop, h_slice\u001b[38;5;241m.\u001b[39mstop))\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/PIL/Image.py:3147\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m accept_warnings:\n\u001b[1;32m   3146\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[0;32m-> 3147\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(\n\u001b[1;32m   3148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[1;32m   3149\u001b[0m )\n",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file '/home/qalmaqihir/scikit_learn_data/lfw_home/lfw_funneled/Alejandro_Toledo/Alejandro_Toledo_0031.jpg'"
     ]
    }
   ],
   "source": [
    "# from sklearn.datasets import fetch_lfw_people\n",
    "# faces = fetch_lfw_people(min_faces_per_person=30)\n",
    "# faces.data.shape\n",
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "faces = fetch_lfw_people(min_faces_per_person=30)\n",
    "faces.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdafb085",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'faces' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m8\u001b[39m, subplot_kw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(xticks\u001b[38;5;241m=\u001b[39m[], yticks\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, axi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ax\u001b[38;5;241m.\u001b[39mflat):\n\u001b[0;32m----> 3\u001b[0m     axi\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mfaces\u001b[49m\u001b[38;5;241m.\u001b[39mimages[i], cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'faces' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAEhUlEQVR4nO3cMW7jQBQFwU/CmSPd/5CKnJJ7g6UEmG0PXBVP8Jh0MNBoO8/zHAAS+08PAPhLRBcgJLoAIdEFCIkuQEh0AUIfVweez685jp//Vdm+b/N4fP73jK3vWWXnjK13WWXrKjtnrrdeRvc4zl/xIa+w9futsnPG1russnWVna4XAEKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKEPq4O7PtW7Lj0yg5b37PKzhlb77LK1lV2zlzv2M7zPKMtAH+e6wWAkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2A0OUz4Ofza47j5x+t7fs2j8fnf8/Y+p5Vds7YepdVtq6yc+Z662V0j+P8FR/yClu/3yo7Z2y9yypbV9npegEgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCH1cHdj3rdhx6ZUdtr5nlZ0ztt5lla2r7Jy53rGd53lGWwD+PNcLACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQhd/vfC8/k1x/HzL4X3fZvH4/O/Z2x9zyo7Z2y9yypbV9k5c731MrrHcf6KD3mFrd9vlZ0ztt5lla2r7HS9ABASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKEPq4O7PtW7Lj0yg5b37PKzhlb77LK1lV2zlzv2M7zPKMtAH+e6wWAkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChC7/e+H5/Jrj+PmXwvu+zePx+d8ztr5nlZ0ztt5lla2r7Jy53noZ3eM4f8WHvMLW77fKzhlb77LK1lV2ul4ACIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUIfVwf2fSt2XHplh63vWWXnjK13WWXrKjtnrnds53me0RaAP8/1AkBIdAFCogsQEl2AkOgChEQXIPQPKL6V3TSHv6MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(4, 8, subplot_kw=dict(xticks=[], yticks=[]))\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(faces.images[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b88840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
